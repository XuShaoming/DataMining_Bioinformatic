{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mylibrary as mylib\n",
    "from mylibrary import NominalFeature\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        \n",
    "class BodyNode:\n",
    "    def __init__(self, feature_id, children):\n",
    "        self.feature_id = feature_id\n",
    "        self.children = children\n",
    "        \n",
    "    def add_child(self, name, child):\n",
    "        self.children[name] = child\n",
    "    def set_id(self, f_id):\n",
    "        self.feature_id = f_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeFactory:\n",
    "    \n",
    "    def __init__(self, training_data, training_label):\n",
    "        self.training_data = training_data\n",
    "        self.training_label = training_label\n",
    "        \n",
    "    def convert_label(self, label, new_neg=-1, new_pos=1, old_neg=0, old_pos=1):\n",
    "        new_label = np.zeros(label.shape)\n",
    "        new_label[label == old_neg] = new_neg\n",
    "        new_label[label == old_pos] = new_pos\n",
    "        return new_label\n",
    "    \n",
    "    def scale_features(self, gate_num):\n",
    "        gates = []\n",
    "        NominalFeatures = []\n",
    "        data_t = []\n",
    "        for i, row in enumerate(self.training_data.T):\n",
    "            try:\n",
    "                float(row[0])\n",
    "                row = row.astype(float)\n",
    "                old_min = np.min(row)\n",
    "                old_max = np.max(row)\n",
    "                gate = np.linspace(old_min, old_max, num=gate_num + 1)\n",
    "                gates.append(gate)\n",
    "                new_row = np.zeros(row.shape)\n",
    "                for j in range(1, len(gate) - 1):\n",
    "                    if j == 1:\n",
    "                        new_row[row < gate[j]] = j\n",
    "                    elif j < len(gate) - 2:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                    else:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                        new_row[row >= gate[j]] = j+1\n",
    "                data_t.append(new_row)\n",
    "            except ValueError:\n",
    "                members = list(set(row))\n",
    "                NominalFeatures.append(NominalFeature(i, members))\n",
    "                new_row = np.asarray([members.index(x) for x in row])\n",
    "                old_min = 0\n",
    "                old_max = len(members) - 1\n",
    "                gate = np.linspace(old_min, old_max, num=len(members))\n",
    "                gates.append(gate)\n",
    "                data_t.append(new_row)\n",
    "                \n",
    "        return np.asarray(data_t).T, gates, NominalFeatures\n",
    "        \n",
    "    def best_split(self, check_data, check_label, impurity_fun):\n",
    "        count = Counter(check_label)\n",
    "        parent_stat = [count[-1], count[1]]\n",
    "        gains = []\n",
    "        for row in check_data.T:\n",
    "            stat = {}\n",
    "            for i, member in enumerate(row):\n",
    "                if member not in stat:\n",
    "                    stat[member] = [0,0]\n",
    "                if check_label[i] == -1:\n",
    "                    stat[member][0] += 1\n",
    "                else:\n",
    "                    stat[member][1] += 1\n",
    "            gains.append(mylib.gain(parent_stat ,list(stat.values()), impurity_fun))\n",
    "        gains = np.asarray(gains)\n",
    "        \n",
    "        return np.argmax(gains)\n",
    "    \n",
    "    \n",
    "    def create_node(self, check_data, check_label):\n",
    "        label_set = set(check_label)\n",
    "        #all training samples have same label\n",
    "        if len(label_set) == 1:\n",
    "            return LeafNode(check_label[0])\n",
    "        # identical features\n",
    "        if check_data.shape[1] == 1:\n",
    "            # may introduce some False\n",
    "            return LeafNode(max(check_label, key=Counter(check_label).get))\n",
    "        \n",
    "        return BodyNode(-1, dict())\n",
    "    \n",
    "    def get_children(self, check_data, feature_id):\n",
    "        feature = check_data.T[feature_id]\n",
    "        members = set(feature)\n",
    "        member_dict = dict()\n",
    "        for member in members:\n",
    "            member_dict[member] = np.where(feature == member)[0] \n",
    "        return member_dict\n",
    "        \n",
    "    def tree_growth(self, data, label,Es, Fs, impurity_fun):\n",
    "        Es_list = np.asarray(list(Es))\n",
    "        Fs_list = np.asarray(list(Fs))\n",
    "        check_data = data[Es_list, :][:, Fs_list]\n",
    "        check_label = label[Es_list]\n",
    "        node = self.create_node(check_data, check_label)\n",
    "        if type(node) is LeafNode:\n",
    "            return node\n",
    "        else:\n",
    "            feature_virtual_id = self.best_split(check_data, check_label, impurity_fun)\n",
    "            feature_actual_id = Fs_list[feature_virtual_id]\n",
    "            node.set_id(feature_actual_id)\n",
    "            new_Fs = Fs - set([feature_actual_id])\n",
    "            children_dict = self.get_children(check_data, feature_virtual_id)\n",
    "            \n",
    "            #handle unconvered memebers\n",
    "            feature_members = set(data[:, feature_actual_id])\n",
    "            c_feature_members = set(children_dict.keys())\n",
    "            uncovered_members = feature_members - c_feature_members\n",
    "            guess_label = max(check_label, key=Counter(check_label).get)\n",
    "            for name in uncovered_members:\n",
    "                node.add_child(name, LeafNode(guess_label))\n",
    "    \n",
    "            del check_data\n",
    "            del check_label\n",
    "            for name, Evs_vitual_list in children_dict.items():\n",
    "                Evs = set(Es_list[Evs_vitual_list])\n",
    "                child = self.tree_growth(data, label, Evs, new_Fs, impurity_fun)\n",
    "                node.add_child(name, child)\n",
    "        return node\n",
    "    \n",
    "    def get_DT_machine(self, gate_num, impurity_fun):\n",
    "        data, gates, nominal_features = self.scale_features(gate_num)\n",
    "        label = self.convert_label(self.training_label)\n",
    "        Es = set(range(data.shape[0]))\n",
    "        Fs = set(range(data.shape[1]))\n",
    "        root = self.tree_growth(data, label, Es, Fs, impurity_fun)\n",
    "        \n",
    "        return DT_machine(root, gates, nominal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT_machine:\n",
    "    def __init__(self, root, gates, nominal_features):\n",
    "        self.root = root\n",
    "        self.gates = gates.copy()\n",
    "        self.nominal_features = nominal_features.copy()\n",
    "    \n",
    "    def preprocess(self, the_data):\n",
    "        data_t = []\n",
    "        nominal_ids = [obj.col_id for obj in self.nominal_features]\n",
    "        nominal_loc = 0\n",
    "        \n",
    "        for i, row in enumerate(the_data.T):\n",
    "            if i not in nominal_ids:\n",
    "                row = row.astype(float)\n",
    "                new_row = np.zeros(row.shape)\n",
    "                gate = self.gates[i]\n",
    "                for j in range(1, len(gate) - 1):\n",
    "                    if j == 1:\n",
    "                        new_row[row < gate[j]] = j\n",
    "                    elif j < len(gate) - 2:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                    else:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                        new_row[row >= gate[j]] = j+1\n",
    "                data_t.append(new_row)\n",
    "            else:\n",
    "                nominal = self.nominal_features[nominal_loc]\n",
    "                new_row = np.asarray([nominal.members.index(x) for x in row])\n",
    "                data_t.append(new_row)\n",
    "                nominal_loc += 1\n",
    "                \n",
    "        return np.asarray(data_t).T\n",
    "    \n",
    "    def predict_aux(self, node, entry):\n",
    "        if type(node) is LeafNode:\n",
    "            return node.label\n",
    "        return self.predict_aux(node.children[entry[node.feature_id]], entry)\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        data_test = self.preprocess(test_data)\n",
    "        res_label = []\n",
    "        for row in data_test:\n",
    "            res_label.append(self.predict_aux(self.root, row))\n",
    "        return np.asarray(res_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_res(raw_set, n, gate_num):\n",
    "    \n",
    "    for i in range(n):\n",
    "        training_set, test_set = mylib.n_fold(n ,i, raw_set)\n",
    "        training_data, training_label = mylib.get_data_label(training_set)\n",
    "        factory = TreeFactory(training_data, training_label)\n",
    "        dtree = factory.get_DT_machine(gate_num, mylib.entropy)\n",
    "        test_data, test_label = mylib.get_data_label(test_set)\n",
    "        true_label = factory.convert_label(test_label)\n",
    "        res_label = dtree.predict(test_data)\n",
    "        confusion = mylib.confusion_matrix(true_label, res_label)\n",
    "        accuracy = mylib.get_accuracy(confusion)\n",
    "        precision = mylib.get_precision(confusion)\n",
    "        recall = mylib.get_recall(confusion)\n",
    "        f1_score = mylib.get_f1_score(confusion)\n",
    "        print(\"**************itr: \", i,\" **************\")\n",
    "        print(\"confusion matrix:\")\n",
    "        print(confusion)\n",
    "        print(\"accuracy: \", accuracy)\n",
    "        print(\"precision: \", precision)\n",
    "        print(\"recall: \", recall)\n",
    "        print(\"f1_score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************itr:  0  **************\n",
      "confusion matrix:\n",
      "[[20  2]\n",
      " [ 3 31]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.8695652173913043\n",
      "recall:  0.9090909090909091\n",
      "f1_score:  0.8888888888888888\n",
      "**************itr:  1  **************\n",
      "confusion matrix:\n",
      "[[15  3]\n",
      " [ 2 36]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.8823529411764706\n",
      "recall:  0.8333333333333334\n",
      "f1_score:  0.8571428571428571\n",
      "**************itr:  2  **************\n",
      "confusion matrix:\n",
      "[[11  1]\n",
      " [ 3 41]]\n",
      "accuracy:  0.9285714285714286\n",
      "precision:  0.7857142857142857\n",
      "recall:  0.9166666666666666\n",
      "f1_score:  0.8461538461538461\n",
      "**************itr:  3  **************\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3 32]]\n",
      "accuracy:  0.9285714285714286\n",
      "precision:  0.8695652173913043\n",
      "recall:  0.9523809523809523\n",
      "f1_score:  0.9090909090909091\n",
      "**************itr:  4  **************\n",
      "confusion matrix:\n",
      "[[21  1]\n",
      " [ 3 31]]\n",
      "accuracy:  0.9285714285714286\n",
      "precision:  0.875\n",
      "recall:  0.9545454545454546\n",
      "f1_score:  0.9130434782608695\n",
      "**************itr:  5  **************\n",
      "confusion matrix:\n",
      "[[18  3]\n",
      " [ 0 35]]\n",
      "accuracy:  0.9464285714285714\n",
      "precision:  1.0\n",
      "recall:  0.8571428571428571\n",
      "f1_score:  0.9230769230769231\n",
      "**************itr:  6  **************\n",
      "confusion matrix:\n",
      "[[26  0]\n",
      " [ 0 30]]\n",
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "**************itr:  7  **************\n",
      "confusion matrix:\n",
      "[[13  2]\n",
      " [ 1 40]]\n",
      "accuracy:  0.9464285714285714\n",
      "precision:  0.9285714285714286\n",
      "recall:  0.8666666666666667\n",
      "f1_score:  0.896551724137931\n",
      "**************itr:  8  **************\n",
      "confusion matrix:\n",
      "[[23  4]\n",
      " [ 1 28]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.9583333333333334\n",
      "recall:  0.8518518518518519\n",
      "f1_score:  0.9019607843137255\n",
      "**************itr:  9  **************\n",
      "confusion matrix:\n",
      "[[23  3]\n",
      " [ 3 27]]\n",
      "accuracy:  0.8928571428571429\n",
      "precision:  0.8846153846153846\n",
      "recall:  0.8846153846153846\n",
      "f1_score:  0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "branch_num = 4\n",
    "raw_set= mylib.get_set(\"../data/project3_dataset1.txt\")\n",
    "show_res(raw_set, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_set= mylib.get_set(\"../data/project3_dataset1.txt\")\n",
    "training_set, test_set = mylib.n_fold(10 ,0, raw_set)\n",
    "training_data, training_label = mylib.get_data_label(training_set)\n",
    "factory = TreeFactory(training_data, training_label)\n",
    "dtree = factory.get_DT_machine(4, mylib.entropy)\n",
    "test_data, test_label = mylib.get_data_label(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_label = dtree.predict(test_data)\n",
    "true_label = factory.convert_label(test_label)\n",
    "res_label == true_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
