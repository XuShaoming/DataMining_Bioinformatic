{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mylibrary as mylib\n",
    "from mylibrary import NominalFeature\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        \n",
    "class BodyNode:\n",
    "    def __init__(self, feature_id, children):\n",
    "        self.feature_id = feature_id\n",
    "        self.children = children\n",
    "        \n",
    "    def add_child(self, name, child):\n",
    "        self.children[name] = child\n",
    "    def set_id(self, f_id):\n",
    "        self.feature_id = f_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeFactory:\n",
    "    \n",
    "    def __init__(self, training_data, training_label):\n",
    "        self.training_data = training_data\n",
    "        self.training_label = training_label\n",
    "    \n",
    "    def scale_features(self, gate_num):\n",
    "        gates = []\n",
    "        NominalFeatures = []\n",
    "        data_t = []\n",
    "        for i, row in enumerate(self.training_data.T):\n",
    "            try:\n",
    "                float(row[0])\n",
    "                row = row.astype(float)\n",
    "                old_min = np.min(row)\n",
    "                old_max = np.max(row)\n",
    "                gate = np.linspace(old_min, old_max, num=gate_num + 1)\n",
    "                gates.append(gate)\n",
    "                new_row = np.zeros(row.shape)\n",
    "                for j in range(1, len(gate) - 1):\n",
    "                    if j == 1:\n",
    "                        new_row[row < gate[j]] = j\n",
    "                    elif j < len(gate) - 2:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                    else:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                        new_row[row >= gate[j]] = j+1\n",
    "                data_t.append(new_row)\n",
    "            except ValueError:\n",
    "                members = list(set(row))\n",
    "                NominalFeatures.append(NominalFeature(i, members))\n",
    "                new_row = np.asarray([members.index(x) for x in row])\n",
    "                old_min = 0\n",
    "                old_max = len(members) - 1\n",
    "                gate = np.linspace(old_min, old_max, num=len(members))\n",
    "                gates.append(gate)\n",
    "                data_t.append(new_row)\n",
    "                \n",
    "        return np.asarray(data_t).T, gates, NominalFeatures\n",
    "        \n",
    "    def best_split(self, check_data, check_label, impurity_fun):\n",
    "        count = Counter(check_label)\n",
    "        parent_stat = [count[-1], count[1]]\n",
    "        gains = []\n",
    "        for row in check_data.T:\n",
    "            stat = {}\n",
    "            for i, member in enumerate(row):\n",
    "                if member not in stat:\n",
    "                    stat[member] = [0,0]\n",
    "                if check_label[i] == -1:\n",
    "                    stat[member][0] += 1\n",
    "                else:\n",
    "                    stat[member][1] += 1\n",
    "            gains.append(mylib.gain(parent_stat ,list(stat.values()), impurity_fun))\n",
    "        gains = np.asarray(gains)\n",
    "        \n",
    "        return np.argmax(gains)\n",
    "    \n",
    "    \n",
    "    def create_node(self, check_data, check_label):\n",
    "        label_set = set(check_label)\n",
    "        #all training samples have same label\n",
    "        if len(label_set) == 1:\n",
    "            return LeafNode(check_label[0])\n",
    "        # identical features\n",
    "        if check_data.shape[1] == 1:\n",
    "            # may introduce some False\n",
    "            return LeafNode(max(check_label, key=Counter(check_label).get))\n",
    "        \n",
    "        return BodyNode(-1, dict())\n",
    "    \n",
    "    def get_children(self, check_data, feature_id):\n",
    "        feature = check_data.T[feature_id]\n",
    "        members = set(feature)\n",
    "        member_dict = dict()\n",
    "        for member in members:\n",
    "            member_dict[member] = np.where(feature == member)[0] \n",
    "        return member_dict\n",
    "        \n",
    "    def tree_growth(self, data, label,Es, Fs, gate_num, impurity_fun, sub_space_fun, rand):\n",
    "        Es_list = np.asarray(list(Es))\n",
    "        Fs_list = np.asarray(list(Fs))\n",
    "        #chose a subset of features \n",
    "        sub_Fs_num = sub_space_fun(len(Fs_list))\n",
    "        Fs_list = Fs_list[rand.permutation(len(Fs_list))[0:sub_Fs_num]]\n",
    "        \n",
    "        check_data = data[Es_list, :][:, Fs_list]\n",
    "        check_label = label[Es_list]\n",
    "        node = self.create_node(check_data, check_label)\n",
    "        if type(node) is LeafNode:\n",
    "            return node\n",
    "        else:\n",
    "            feature_virtual_id = self.best_split(check_data, check_label, impurity_fun)\n",
    "            feature_actual_id = Fs_list[feature_virtual_id]\n",
    "            node.set_id(feature_actual_id)\n",
    "            new_Fs = Fs - set([feature_actual_id])\n",
    "            children_dict = self.get_children(check_data, feature_virtual_id)\n",
    "            \n",
    "            #majority vote for unseen samples\n",
    "            feature_members = set(data[:, feature_actual_id])\n",
    "            # not nominal feature and the the feature members not completed\n",
    "            if min(list(feature_members)) != 0 and len(feature_members) != gate_num:\n",
    "                feature_members = set(range(1, gate_num + 1))\n",
    "            c_feature_members = set(children_dict.keys())\n",
    "            uncovered_members = feature_members - c_feature_members\n",
    "            guess_label = max(check_label, key=Counter(check_label).get)\n",
    "            for name in uncovered_members:\n",
    "                node.add_child(name, LeafNode(guess_label))\n",
    "    \n",
    "            del check_data\n",
    "            del check_label\n",
    "            for name, Evs_vitual_list in children_dict.items():\n",
    "                Evs = set(Es_list[Evs_vitual_list])\n",
    "                child = self.tree_growth(data, label, Evs, new_Fs, gate_num, impurity_fun, sub_space_fun, rand)\n",
    "                node.add_child(name, child)\n",
    "        return node\n",
    "    \n",
    "    def get_DT_machine(self, gate_num, impurity_fun, sub_space_fun, seed):\n",
    "        data, gates, nominal_features = self.scale_features(gate_num)\n",
    "        label = mylib.convert_label(self.training_label)\n",
    "        rand = np.random.RandomState(seed)\n",
    "        Es = set(range(data.shape[0]))\n",
    "        Fs = set(range(data.shape[1]))\n",
    "        root = self.tree_growth(data, label, Es, Fs, gate_num, impurity_fun, sub_space_fun, rand)\n",
    "        \n",
    "        return DT_machine(root, gates, nominal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT_machine:\n",
    "    def __init__(self, root, gates, nominal_features):\n",
    "        self.root = root\n",
    "        self.gates = gates.copy()\n",
    "        self.nominal_features = nominal_features.copy()\n",
    "    \n",
    "    def preprocess(self, the_data):\n",
    "        data_t = []\n",
    "        nominal_ids = [obj.col_id for obj in self.nominal_features]\n",
    "        nominal_loc = 0\n",
    "        \n",
    "        for i, row in enumerate(the_data.T):\n",
    "            if i not in nominal_ids:\n",
    "                row = row.astype(float)\n",
    "                new_row = np.zeros(row.shape)\n",
    "                gate = self.gates[i]\n",
    "                for j in range(1, len(gate) - 1):\n",
    "                    if j == 1:\n",
    "                        new_row[row < gate[j]] = j\n",
    "                    elif j < len(gate) - 2:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                    else:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row < gate[j])]] = j\n",
    "                        new_row[row >= gate[j]] = j+1\n",
    "                data_t.append(new_row)\n",
    "            else:\n",
    "                nominal = self.nominal_features[nominal_loc]\n",
    "                new_row = np.asarray([nominal.members.index(x) for x in row])\n",
    "                data_t.append(new_row)\n",
    "                nominal_loc += 1\n",
    "                \n",
    "        return np.asarray(data_t).T\n",
    "    \n",
    "    def predict_aux(self, node, entry):\n",
    "\n",
    "        if type(node) is LeafNode:\n",
    "            return node.label\n",
    "        return self.predict_aux(node.children[entry[node.feature_id]], entry)\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        data_test = self.preprocess(test_data)\n",
    "        res_label = []\n",
    "        for row in data_test:\n",
    "            res_label.append(self.predict_aux(self.root, row))\n",
    "        return np.asarray(res_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_p(method=1):\n",
    "    \"\"\"\n",
    "    recommend:\n",
    "        method_1 for single Tree\n",
    "        method_2 for Classification problem\n",
    "        method_3 for regression problem\n",
    "    \"\"\"\n",
    "    def method_1(p):\n",
    "        return p\n",
    "    def method_2(p):\n",
    "        return int(np.log2(p))\n",
    "    def method_3(p):\n",
    "        return int(p/3)\n",
    "    \n",
    "    if method == 2:\n",
    "        return method_2\n",
    "    elif method == 3:\n",
    "        return method_3\n",
    "    else:\n",
    "        return method_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_res(raw_set, n, gate_num, sub_space_fun, seed):\n",
    "    \n",
    "    for i in range(n):\n",
    "        training_set, test_set = mylib.n_fold(n ,i, raw_set)\n",
    "        training_data, training_label = mylib.get_data_label(training_set)\n",
    "        factory = TreeFactory(training_data, training_label)\n",
    "        \n",
    "        dtree = factory.get_DT_machine(gate_num, mylib.entropy, sub_space_fun, seed)\n",
    "        test_data, test_label = mylib.get_data_label(test_set)\n",
    "        true_label = mylib.convert_label(test_label)\n",
    "        res_label = dtree.predict(test_data)\n",
    "        confusion = mylib.confusion_matrix(true_label, res_label)\n",
    "        accuracy = mylib.get_accuracy(confusion)\n",
    "        precision = mylib.get_precision(confusion)\n",
    "        recall = mylib.get_recall(confusion)\n",
    "        f1_score = mylib.get_f1_score(confusion)\n",
    "        print(\"**************itr: \", i,\" **************\")\n",
    "        print(\"confusion matrix:\")\n",
    "        print(confusion)\n",
    "        print(\"accuracy: \", accuracy)\n",
    "        print(\"precision: \", precision)\n",
    "        print(\"recall: \", recall)\n",
    "        print(\"f1_score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************project3_dataset1*****************\n",
      "**************itr:  0  **************\n",
      "confusion matrix:\n",
      "[[20  2]\n",
      " [ 5 29]]\n",
      "accuracy:  0.875\n",
      "precision:  0.8\n",
      "recall:  0.9090909090909091\n",
      "f1_score:  0.851063829787234\n",
      "**************itr:  1  **************\n",
      "confusion matrix:\n",
      "[[17  1]\n",
      " [ 1 37]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  0.9444444444444444\n",
      "recall:  0.9444444444444444\n",
      "f1_score:  0.9444444444444444\n",
      "**************itr:  2  **************\n",
      "confusion matrix:\n",
      "[[ 9  3]\n",
      " [ 3 41]]\n",
      "accuracy:  0.8928571428571429\n",
      "precision:  0.75\n",
      "recall:  0.75\n",
      "f1_score:  0.75\n",
      "**************itr:  3  **************\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 4 31]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.8333333333333334\n",
      "recall:  0.9523809523809523\n",
      "f1_score:  0.8888888888888888\n",
      "**************itr:  4  **************\n",
      "confusion matrix:\n",
      "[[18  4]\n",
      " [ 2 32]]\n",
      "accuracy:  0.8928571428571429\n",
      "precision:  0.9\n",
      "recall:  0.8181818181818182\n",
      "f1_score:  0.8571428571428571\n",
      "**************itr:  5  **************\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 0 35]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  1.0\n",
      "recall:  0.9047619047619048\n",
      "f1_score:  0.95\n",
      "**************itr:  6  **************\n",
      "confusion matrix:\n",
      "[[24  2]\n",
      " [ 2 28]]\n",
      "accuracy:  0.9285714285714286\n",
      "precision:  0.9230769230769231\n",
      "recall:  0.9230769230769231\n",
      "f1_score:  0.9230769230769231\n",
      "**************itr:  7  **************\n",
      "confusion matrix:\n",
      "[[14  1]\n",
      " [ 1 40]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  0.9333333333333333\n",
      "recall:  0.9333333333333333\n",
      "f1_score:  0.9333333333333333\n",
      "**************itr:  8  **************\n",
      "confusion matrix:\n",
      "[[21  6]\n",
      " [ 0 29]]\n",
      "accuracy:  0.8928571428571429\n",
      "precision:  1.0\n",
      "recall:  0.7777777777777778\n",
      "f1_score:  0.875\n",
      "**************itr:  9  **************\n",
      "confusion matrix:\n",
      "[[24  2]\n",
      " [ 2 28]]\n",
      "accuracy:  0.9285714285714286\n",
      "precision:  0.9230769230769231\n",
      "recall:  0.9230769230769231\n",
      "f1_score:  0.9230769230769231\n",
      "\n",
      "\n",
      "***************project3_dataset2*****************\n",
      "**************itr:  0  **************\n",
      "confusion matrix:\n",
      "[[ 8 13]\n",
      " [ 7 18]]\n",
      "accuracy:  0.5652173913043478\n",
      "precision:  0.5333333333333333\n",
      "recall:  0.38095238095238093\n",
      "f1_score:  0.4444444444444444\n",
      "**************itr:  1  **************\n",
      "confusion matrix:\n",
      "[[ 4  8]\n",
      " [ 7 27]]\n",
      "accuracy:  0.6739130434782609\n",
      "precision:  0.36363636363636365\n",
      "recall:  0.3333333333333333\n",
      "f1_score:  0.34782608695652173\n",
      "**************itr:  2  **************\n",
      "confusion matrix:\n",
      "[[10  9]\n",
      " [ 5 22]]\n",
      "accuracy:  0.6956521739130435\n",
      "precision:  0.6666666666666666\n",
      "recall:  0.5263157894736842\n",
      "f1_score:  0.5882352941176471\n",
      "**************itr:  3  **************\n",
      "confusion matrix:\n",
      "[[ 5 10]\n",
      " [ 9 22]]\n",
      "accuracy:  0.5869565217391305\n",
      "precision:  0.35714285714285715\n",
      "recall:  0.3333333333333333\n",
      "f1_score:  0.3448275862068966\n",
      "**************itr:  4  **************\n",
      "confusion matrix:\n",
      "[[ 3 18]\n",
      " [ 3 22]]\n",
      "accuracy:  0.5434782608695652\n",
      "precision:  0.5\n",
      "recall:  0.14285714285714285\n",
      "f1_score:  0.2222222222222222\n",
      "**************itr:  5  **************\n",
      "confusion matrix:\n",
      "[[ 4 14]\n",
      " [10 18]]\n",
      "accuracy:  0.4782608695652174\n",
      "precision:  0.2857142857142857\n",
      "recall:  0.2222222222222222\n",
      "f1_score:  0.25\n",
      "**************itr:  6  **************\n",
      "confusion matrix:\n",
      "[[ 8  5]\n",
      " [ 8 25]]\n",
      "accuracy:  0.717391304347826\n",
      "precision:  0.5\n",
      "recall:  0.6153846153846154\n",
      "f1_score:  0.5517241379310345\n",
      "**************itr:  7  **************\n",
      "confusion matrix:\n",
      "[[ 5  5]\n",
      " [ 7 29]]\n",
      "accuracy:  0.7391304347826086\n",
      "precision:  0.4166666666666667\n",
      "recall:  0.5\n",
      "f1_score:  0.45454545454545453\n",
      "**************itr:  8  **************\n",
      "confusion matrix:\n",
      "[[ 2 14]\n",
      " [ 5 25]]\n",
      "accuracy:  0.5869565217391305\n",
      "precision:  0.2857142857142857\n",
      "recall:  0.125\n",
      "f1_score:  0.17391304347826086\n",
      "**************itr:  9  **************\n",
      "confusion matrix:\n",
      "[[ 7  7]\n",
      " [ 8 24]]\n",
      "accuracy:  0.6739130434782609\n",
      "precision:  0.4666666666666667\n",
      "recall:  0.5\n",
      "f1_score:  0.4827586206896552\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    n = 10\n",
    "    branch_num = 4\n",
    "    sub_space_fun = sub_p(2)\n",
    "    seed = 20\n",
    "    print(\"***************project3_dataset1*****************\")\n",
    "    raw_set= mylib.get_set(\"../data/project3_dataset1.txt\")\n",
    "    show_res(raw_set, n, branch_num, sub_space_fun, seed)\n",
    "    print(\"\\n\\n***************project3_dataset2*****************\")\n",
    "    raw_set= mylib.get_set(\"../data/project3_dataset2.txt\")\n",
    "    show_res(raw_set, n, branch_num, sub_space_fun, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "raw_set= mylib.get_set(\"../data/project3_dataset1.txt\")\n",
    "training_set, test_set = mylib.n_fold(10 ,0, raw_set)\n",
    "training_data, training_label = mylib.get_data_label(training_set)\n",
    "factory = TreeFactory(training_data, training_label)\n",
    "dtree = factory.get_DT_machine(4, mylib.entropy, sub_space_fun, seed)\n",
    "test_data, test_label = mylib.get_data_label(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
