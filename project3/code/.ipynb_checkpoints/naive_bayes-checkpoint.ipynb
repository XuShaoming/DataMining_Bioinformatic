{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mylibrary as mylib\n",
    "from mylibrary import NominalFeature\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesFactory:\n",
    "    \n",
    "    def __init__(self, training_data, training_label):\n",
    "        self.training_data = training_data\n",
    "        self.training_label = training_label\n",
    "    \n",
    "    def scale_features(self, section_num):\n",
    "        gates = []\n",
    "        NominalFeatures = []\n",
    "        data_t = []\n",
    "        for i, row in enumerate(self.training_data.T):\n",
    "            try:\n",
    "                float(row[0])\n",
    "                row = row.astype(float)\n",
    "                old_min = np.min(row)\n",
    "                old_max = np.max(row)\n",
    "                gate = np.linspace(old_min, old_max, num=section_num-1)\n",
    "                gates.append(gate)\n",
    "                new_row = np.zeros(row.shape)\n",
    "                for j in range(len(gate)):\n",
    "                    if j == 0:\n",
    "                        new_row[row < gate[j]] = j\n",
    "                    elif j == 1:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row <= gate[j])]] = j\n",
    "                    elif j < len(gate) - 1:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] < row, row <= gate[j])]] = j\n",
    "                    else:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] < row, row <= gate[j])]] = j\n",
    "                        new_row[row > gate[j]] = j+1\n",
    "                data_t.append(new_row)\n",
    "            except ValueError:\n",
    "                members = list(set(row))\n",
    "                NominalFeatures.append(NominalFeature(i, members))\n",
    "                new_row = np.asarray([members.index(x) for x in row])\n",
    "                old_min = 0\n",
    "                old_max = len(members) - 1\n",
    "                gate = np.linspace(old_min, old_max, num=len(members))\n",
    "                gates.append(gate)\n",
    "                data_t.append(new_row)\n",
    "                \n",
    "        return np.asarray(data_t).T, gates, NominalFeatures\n",
    "    \n",
    "    def get_naiveBayes_machine(self, sect_num):\n",
    "        data, gates, nominal_features = self.scale_features(sect_num)\n",
    "        nominal_ids = [obj.col_id for obj in nominal_features]\n",
    "        \n",
    "        n = len(self.training_label)\n",
    "        counter = Counter(self.training_label)\n",
    "        n1 = counter[1]\n",
    "        n0 = counter[0]\n",
    "        p0 = n0 / n\n",
    "        p1 = n1 / n\n",
    "        features = []\n",
    "        for i, row in enumerate(data.T):\n",
    "            count = {}\n",
    "            for j, member in enumerate(row):\n",
    "                if member not in count:\n",
    "                    count[member] = [0,0]\n",
    "                if self.training_label[j] == 1:\n",
    "                    count[member][1] += 1\n",
    "                elif self.training_label[j] == 0:\n",
    "                    count[member][0] += 1\n",
    "            \n",
    "            ##probability for out range data\n",
    "            if i not in nominal_ids:\n",
    "                if 0 not in count:   \n",
    "                    count[0] = [0,0]\n",
    "                if len(count) not in count:\n",
    "                    count[len(count)] = [0,0]\n",
    "                \n",
    "            #Avoiding the Zero-Probability Problem\n",
    "            new_n0 = n0 + len(count)\n",
    "            new_n1 = n1 + len(count)\n",
    "            for k, v in count.items():\n",
    "                v[0] = (v[0] + 1) / new_n0\n",
    "                v[1] = (v[1] + 1) / new_n1\n",
    "                \n",
    "            features.append(count)\n",
    "            \n",
    "        return NaiveBayes_Machine(p0, p1, features, gates, nominal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes_Machine:\n",
    "    def __init__(self, p0, p1, features_stat, gates, nominal_features):\n",
    "        self.p0 = p0\n",
    "        self.p1 = p1\n",
    "        self.features_stat = features_stat.copy()\n",
    "        self.gates = gates.copy()\n",
    "        self.nominal_features = nominal_features.copy()\n",
    "        \n",
    "    def preprocess(self, the_data):\n",
    "        data_t = []\n",
    "        nominal_ids = [obj.col_id for obj in self.nominal_features]\n",
    "        nominal_loc = 0\n",
    "        \n",
    "        for i, row in enumerate(the_data.T):\n",
    "            if i not in nominal_ids:\n",
    "                row = row.astype(float)\n",
    "                new_row = np.zeros(row.shape)\n",
    "                gate = self.gates[i]\n",
    "                for j in range(len(gate)):\n",
    "                    if j == 0:\n",
    "                        new_row[row < gate[j]] = j\n",
    "                    elif j == 1:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] <= row, row <= gate[j])]] = j\n",
    "                    elif j < len(gate) - 1:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] < row, row <= gate[j])]] = j\n",
    "                    else:\n",
    "                        new_row[[x[0] and x[1] for x in zip(gate[j-1] < row, row <= gate[j])]] = j\n",
    "                        new_row[row > gate[j]] = j+1\n",
    "                data_t.append(new_row)\n",
    "            else:\n",
    "                nominal = self.nominal_features[nominal_loc]\n",
    "                new_row = np.asarray([nominal.members.index(x) for x in row])\n",
    "                data_t.append(new_row)\n",
    "                nominal_loc += 1\n",
    "                \n",
    "        return np.asarray(data_t).T   \n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        data_test = self.preprocess(test_data)\n",
    "        res_label = []\n",
    "        for row in data_test:\n",
    "            p_x_given_0 = 1\n",
    "            p_x_given_1 = 1\n",
    "            for i, feature in enumerate(row):\n",
    "                p_x_given_0 *= self.features_stat[i][feature][0]\n",
    "                p_x_given_1 *= self.features_stat[i][feature][1]\n",
    "            check = np.asarray([self.p0 * p_x_given_0, self.p1 * p_x_given_1])\n",
    "            res_label.append(np.argmax(check))\n",
    "            \n",
    "        return np.asarray(res_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_res(raw_set, n, sec_num):\n",
    "    \n",
    "    for i in range(n):\n",
    "        training_set, test_set = mylib.n_fold(n ,i, raw_set)\n",
    "        training_data, training_label = mylib.get_data_label(training_set)\n",
    "        factory = NaiveBayesFactory(training_data, training_label)\n",
    "        bayes_5 = factory.get_naiveBayes_machine(sec_num)\n",
    "        test_data, test_label = mylib.get_data_label(test_set)\n",
    "        res_label = bayes_5.predict(test_data)\n",
    "        confusion = mylib.confusion_matrix(test_label, res_label)\n",
    "        accuracy = mylib.get_accuracy(confusion)\n",
    "        precision = mylib.get_precision(confusion)\n",
    "        recall = mylib.get_recall(confusion)\n",
    "        f1_score = mylib.get_f1_score(confusion)\n",
    "        print(\"**************itr: \", i,\" **************\")\n",
    "        print(\"confusion matrix:\")\n",
    "        print(confusion)\n",
    "        print(\"accuracy: \", accuracy)\n",
    "        print(\"precision: \", precision)\n",
    "        print(\"recall: \", recall)\n",
    "        print(\"f1_score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "sec_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************itr:  0  **************\n",
      "confusion matrix:\n",
      "[[20  2]\n",
      " [ 1 33]]\n",
      "accuracy:  0.9464285714285714\n",
      "precision:  0.9523809523809523\n",
      "recall:  0.9090909090909091\n",
      "f1_score:  0.9302325581395349\n",
      "**************itr:  1  **************\n",
      "confusion matrix:\n",
      "[[15  3]\n",
      " [ 2 36]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.8823529411764706\n",
      "recall:  0.8333333333333334\n",
      "f1_score:  0.8571428571428571\n",
      "**************itr:  2  **************\n",
      "confusion matrix:\n",
      "[[11  1]\n",
      " [ 2 42]]\n",
      "accuracy:  0.9464285714285714\n",
      "precision:  0.8461538461538461\n",
      "recall:  0.9166666666666666\n",
      "f1_score:  0.88\n",
      "**************itr:  3  **************\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 1 34]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  0.9523809523809523\n",
      "recall:  0.9523809523809523\n",
      "f1_score:  0.9523809523809523\n",
      "**************itr:  4  **************\n",
      "confusion matrix:\n",
      "[[20  2]\n",
      " [ 0 34]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  1.0\n",
      "recall:  0.9090909090909091\n",
      "f1_score:  0.9523809523809523\n",
      "**************itr:  5  **************\n",
      "confusion matrix:\n",
      "[[18  3]\n",
      " [ 2 33]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.9\n",
      "recall:  0.8571428571428571\n",
      "f1_score:  0.8780487804878049\n",
      "**************itr:  6  **************\n",
      "confusion matrix:\n",
      "[[25  1]\n",
      " [ 1 29]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  0.9615384615384616\n",
      "recall:  0.9615384615384616\n",
      "f1_score:  0.9615384615384616\n",
      "**************itr:  7  **************\n",
      "confusion matrix:\n",
      "[[14  1]\n",
      " [ 1 40]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  0.9333333333333333\n",
      "recall:  0.9333333333333333\n",
      "f1_score:  0.9333333333333333\n",
      "**************itr:  8  **************\n",
      "confusion matrix:\n",
      "[[23  4]\n",
      " [ 1 28]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.9583333333333334\n",
      "recall:  0.8518518518518519\n",
      "f1_score:  0.9019607843137255\n",
      "**************itr:  9  **************\n",
      "confusion matrix:\n",
      "[[23  3]\n",
      " [ 3 27]]\n",
      "accuracy:  0.8928571428571429\n",
      "precision:  0.8846153846153846\n",
      "recall:  0.8846153846153846\n",
      "f1_score:  0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "raw_set= mylib.get_set(\"../data/project3_dataset1.txt\")\n",
    "show_res(raw_set, n, sec_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************itr:  0  **************\n",
      "confusion matrix:\n",
      "[[13  8]\n",
      " [ 9 16]]\n",
      "accuracy:  0.6304347826086957\n",
      "precision:  0.5909090909090909\n",
      "recall:  0.6190476190476191\n",
      "f1_score:  0.6046511627906976\n",
      "**************itr:  1  **************\n",
      "confusion matrix:\n",
      "[[ 8  4]\n",
      " [12 22]]\n",
      "accuracy:  0.6521739130434783\n",
      "precision:  0.4\n",
      "recall:  0.6666666666666666\n",
      "f1_score:  0.5\n",
      "**************itr:  2  **************\n",
      "confusion matrix:\n",
      "[[12  7]\n",
      " [ 2 25]]\n",
      "accuracy:  0.8043478260869565\n",
      "precision:  0.8571428571428571\n",
      "recall:  0.631578947368421\n",
      "f1_score:  0.7272727272727273\n",
      "**************itr:  3  **************\n",
      "confusion matrix:\n",
      "[[10  5]\n",
      " [ 7 24]]\n",
      "accuracy:  0.7391304347826086\n",
      "precision:  0.5882352941176471\n",
      "recall:  0.6666666666666666\n",
      "f1_score:  0.625\n",
      "**************itr:  4  **************\n",
      "confusion matrix:\n",
      "[[10 11]\n",
      " [ 4 21]]\n",
      "accuracy:  0.6739130434782609\n",
      "precision:  0.7142857142857143\n",
      "recall:  0.47619047619047616\n",
      "f1_score:  0.5714285714285714\n",
      "**************itr:  5  **************\n",
      "confusion matrix:\n",
      "[[ 9  9]\n",
      " [10 18]]\n",
      "accuracy:  0.5869565217391305\n",
      "precision:  0.47368421052631576\n",
      "recall:  0.5\n",
      "f1_score:  0.4864864864864865\n",
      "**************itr:  6  **************\n",
      "confusion matrix:\n",
      "[[ 7  6]\n",
      " [ 3 30]]\n",
      "accuracy:  0.8043478260869565\n",
      "precision:  0.7\n",
      "recall:  0.5384615384615384\n",
      "f1_score:  0.6086956521739131\n",
      "**************itr:  7  **************\n",
      "confusion matrix:\n",
      "[[ 7  3]\n",
      " [ 8 28]]\n",
      "accuracy:  0.7608695652173914\n",
      "precision:  0.4666666666666667\n",
      "recall:  0.7\n",
      "f1_score:  0.56\n",
      "**************itr:  8  **************\n",
      "confusion matrix:\n",
      "[[ 7  9]\n",
      " [13 17]]\n",
      "accuracy:  0.5217391304347826\n",
      "precision:  0.35\n",
      "recall:  0.4375\n",
      "f1_score:  0.3888888888888889\n",
      "**************itr:  9  **************\n",
      "confusion matrix:\n",
      "[[ 8  6]\n",
      " [ 8 24]]\n",
      "accuracy:  0.6956521739130435\n",
      "precision:  0.5\n",
      "recall:  0.5714285714285714\n",
      "f1_score:  0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "raw_set= mylib.get_set(\"../data/project3_dataset2.txt\")\n",
    "show_res(raw_set, n, sec_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
