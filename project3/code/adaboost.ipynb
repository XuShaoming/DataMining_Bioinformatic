{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mylibrary as mylib\n",
    "import decision_tree as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaFactory:\n",
    "    \n",
    "    def __init__(self, training_data, training_label):\n",
    "        self.training_data = training_data\n",
    "        self.training_label = training_label\n",
    "    \n",
    "    def get_AdaMachine(self, k, branch_num=4, impurity_fun=mylib.entropy, sub_space_fun=DT.sub_p(method=2), seed=20):\n",
    "        rand = np.random.RandomState(seed)\n",
    "        n,d = self.training_data.shape\n",
    "        true_label = mylib.convert_label(self.training_label)\n",
    "        vec = np.arange(n)\n",
    "        weights = np.asarray([1/n for i in range(n)])\n",
    "        classifiers = []\n",
    "        importances = []\n",
    "        i = 0\n",
    "        while i < k:\n",
    "            index = rand.choice(vec, n, replace=True, p=weights)\n",
    "            data = self.training_data[index, :]\n",
    "            label = self.training_label[index]\n",
    "            factory = DT.TreeFactory(data, label)\n",
    "            dtree = factory.get_DT_machine(branch_num, impurity_fun, sub_space_fun, seed)\n",
    "            res_label = dtree.predict(self.training_data)\n",
    "            error_vect = res_label != true_label\n",
    "            error = np.sum(weights[error_vect])\n",
    "            if error > 0.5:\n",
    "                print(\"error greater than 0.5\")\n",
    "                #reset weights and go back the head of loop\n",
    "                weights = np.asarray([1/n for i in range(n)])\n",
    "                continue\n",
    "            \n",
    "            ai = 1/2 * np.log((1-error) / error)\n",
    "            \n",
    "            #update weights\n",
    "            X1 =  weights * np.exp(-ai * true_label * res_label)\n",
    "            norm = np.sum(X1)\n",
    "            weights = X1 / norm\n",
    "            \n",
    "            classifiers.append(dtree)\n",
    "            importances.append(ai)\n",
    "            i += 1\n",
    "        \n",
    "        return AdaMachine(classifiers, np.asarray(importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaMachine:\n",
    "    def __init__(self, classifiers, importances):\n",
    "        self.classifiers = classifiers.copy()\n",
    "        self.importances = importances.copy()\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        labels = []\n",
    "        for classifier in self.classifiers:\n",
    "            labels.append(classifier.predict(test_data))\n",
    "        labels = np.asarray(labels)\n",
    "        res = []\n",
    "        for row in labels.T:\n",
    "            res.append(mylib.sign(np.sum(row * self.importances)))\n",
    "        return np.asarray(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_res(raw_set, n, k, branch_num, impurity_fun, sub_space_fun, seed):\n",
    "    \n",
    "    for i in range(n):\n",
    "        training_set, test_set = mylib.n_fold(n ,i, raw_set)\n",
    "        training_data, training_label = mylib.get_data_label(training_set)\n",
    "        factory = AdaFactory(training_data, training_label)\n",
    "        adaForest = factory.get_AdaMachine(k, branch_num, impurity_fun, sub_space_fun, seed)\n",
    "        test_data, test_label = mylib.get_data_label(test_set)\n",
    "        true_label = mylib.convert_label(test_label)\n",
    "        res_label = adaForest.predict(test_data)\n",
    "        confusion = mylib.confusion_matrix(true_label, res_label)\n",
    "        accuracy = mylib.get_accuracy(confusion)\n",
    "        precision = mylib.get_precision(confusion)\n",
    "        recall = mylib.get_recall(confusion)\n",
    "        f1_score = mylib.get_f1_score(confusion)\n",
    "        print(\"**************itr: \", i,\" **************\")\n",
    "        print(\"confusion matrix:\")\n",
    "        print(confusion)\n",
    "        print(\"accuracy: \", accuracy)\n",
    "        print(\"precision: \", precision)\n",
    "        print(\"recall: \", recall)\n",
    "        print(\"f1_score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************project3_dataset1*****************\n",
      "**************itr:  0  **************\n",
      "confusion matrix:\n",
      "[[19  3]\n",
      " [ 2 32]]\n",
      "accuracy:  0.9107142857142857\n",
      "precision:  0.9047619047619048\n",
      "recall:  0.8636363636363636\n",
      "f1_score:  0.8837209302325582\n",
      "**************itr:  1  **************\n",
      "confusion matrix:\n",
      "[[17  1]\n",
      " [ 0 38]]\n",
      "accuracy:  0.9821428571428571\n",
      "precision:  1.0\n",
      "recall:  0.9444444444444444\n",
      "f1_score:  0.9714285714285714\n",
      "**************itr:  2  **************\n",
      "confusion matrix:\n",
      "[[10  2]\n",
      " [ 0 44]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  1.0\n",
      "recall:  0.8333333333333334\n",
      "f1_score:  0.9090909090909091\n",
      "**************itr:  3  **************\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 1 34]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  0.9523809523809523\n",
      "recall:  0.9523809523809523\n",
      "f1_score:  0.9523809523809523\n",
      "**************itr:  4  **************\n",
      "confusion matrix:\n",
      "[[18  4]\n",
      " [ 0 34]]\n",
      "accuracy:  0.9285714285714286\n",
      "precision:  1.0\n",
      "recall:  0.8181818181818182\n",
      "f1_score:  0.9\n",
      "**************itr:  5  **************\n",
      "confusion matrix:\n",
      "[[18  3]\n",
      " [ 1 34]]\n",
      "accuracy:  0.9285714285714286\n",
      "precision:  0.9473684210526315\n",
      "recall:  0.8571428571428571\n",
      "f1_score:  0.9\n",
      "**************itr:  6  **************\n",
      "confusion matrix:\n",
      "[[26  0]\n",
      " [ 0 30]]\n",
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "**************itr:  7  **************\n",
      "confusion matrix:\n",
      "[[14  1]\n",
      " [ 2 39]]\n",
      "accuracy:  0.9464285714285714\n",
      "precision:  0.875\n",
      "recall:  0.9333333333333333\n",
      "f1_score:  0.9032258064516129\n",
      "**************itr:  8  **************\n",
      "confusion matrix:\n",
      "[[25  2]\n",
      " [ 0 29]]\n",
      "accuracy:  0.9642857142857143\n",
      "precision:  1.0\n",
      "recall:  0.9259259259259259\n",
      "f1_score:  0.9615384615384616\n",
      "**************itr:  9  **************\n",
      "confusion matrix:\n",
      "[[21  5]\n",
      " [ 3 27]]\n",
      "accuracy:  0.8571428571428571\n",
      "precision:  0.875\n",
      "recall:  0.8076923076923077\n",
      "f1_score:  0.84\n",
      "\n",
      "\n",
      "\n",
      "***************project3_dataset2*****************\n",
      "**************itr:  0  **************\n",
      "confusion matrix:\n",
      "[[10 11]\n",
      " [ 8 17]]\n",
      "accuracy:  0.5869565217391305\n",
      "precision:  0.5555555555555556\n",
      "recall:  0.47619047619047616\n",
      "f1_score:  0.5128205128205128\n",
      "**************itr:  1  **************\n",
      "confusion matrix:\n",
      "[[ 6  6]\n",
      " [ 7 27]]\n",
      "accuracy:  0.717391304347826\n",
      "precision:  0.46153846153846156\n",
      "recall:  0.5\n",
      "f1_score:  0.48\n",
      "**************itr:  2  **************\n",
      "confusion matrix:\n",
      "[[12  7]\n",
      " [ 6 21]]\n",
      "accuracy:  0.717391304347826\n",
      "precision:  0.6666666666666666\n",
      "recall:  0.631578947368421\n",
      "f1_score:  0.6486486486486487\n",
      "**************itr:  3  **************\n",
      "confusion matrix:\n",
      "[[ 5 10]\n",
      " [ 7 24]]\n",
      "accuracy:  0.6304347826086957\n",
      "precision:  0.4166666666666667\n",
      "recall:  0.3333333333333333\n",
      "f1_score:  0.37037037037037035\n",
      "**************itr:  4  **************\n",
      "confusion matrix:\n",
      "[[ 6 15]\n",
      " [ 2 23]]\n",
      "accuracy:  0.6304347826086957\n",
      "precision:  0.75\n",
      "recall:  0.2857142857142857\n",
      "f1_score:  0.41379310344827586\n",
      "**************itr:  5  **************\n",
      "confusion matrix:\n",
      "[[ 8 10]\n",
      " [ 5 23]]\n",
      "accuracy:  0.6739130434782609\n",
      "precision:  0.6153846153846154\n",
      "recall:  0.4444444444444444\n",
      "f1_score:  0.5161290322580645\n",
      "**************itr:  6  **************\n",
      "confusion matrix:\n",
      "[[ 4  9]\n",
      " [10 23]]\n",
      "accuracy:  0.5869565217391305\n",
      "precision:  0.2857142857142857\n",
      "recall:  0.3076923076923077\n",
      "f1_score:  0.2962962962962963\n",
      "**************itr:  7  **************\n",
      "confusion matrix:\n",
      "[[ 5  5]\n",
      " [ 7 29]]\n",
      "accuracy:  0.7391304347826086\n",
      "precision:  0.4166666666666667\n",
      "recall:  0.5\n",
      "f1_score:  0.45454545454545453\n",
      "**************itr:  8  **************\n",
      "confusion matrix:\n",
      "[[ 3 13]\n",
      " [10 20]]\n",
      "accuracy:  0.5\n",
      "precision:  0.23076923076923078\n",
      "recall:  0.1875\n",
      "f1_score:  0.20689655172413793\n",
      "**************itr:  9  **************\n",
      "confusion matrix:\n",
      "[[ 8  6]\n",
      " [ 9 23]]\n",
      "accuracy:  0.6739130434782609\n",
      "precision:  0.47058823529411764\n",
      "recall:  0.5714285714285714\n",
      "f1_score:  0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    n = 10\n",
    "    k = 30\n",
    "    branch_num = 4\n",
    "    impurity_fun = mylib.entropy\n",
    "    sub_space_fun = DT.sub_p(method=2)\n",
    "    seed = 20\n",
    "\n",
    "    print(\"***************project3_dataset1*****************\")\n",
    "    raw_set= mylib.get_set(\"../data/project3_dataset1.txt\")\n",
    "    show_res(raw_set, n, k, branch_num, impurity_fun, sub_space_fun, seed)\n",
    "    print(\"\\n\\n\\n***************project3_dataset2*****************\")\n",
    "    raw_set= mylib.get_set(\"../data/project3_dataset2.txt\")\n",
    "    show_res(raw_set, n, k, branch_num, impurity_fun, sub_space_fun, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
